- Optimizers에 대한 이해
- Learning Rate Scheduling에 대한 이해
- https://hiddenbeginner.github.io/deeplearning/paperreview/2019/12/29/paper_review_AdamW.html
- Gradient Vanishing and Exploding 문제에 대한 해결책
	- ReLU, ReLU의 변형
	- Gradient Clipping
	- Weight Initialization
	- Batch Normalization
	- Layer Normalization
- https://wikidocs.net/61375
-
	-